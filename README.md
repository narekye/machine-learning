# Supervised learning algorithms

> Attention: In all supervised learning algorithms used the same data.

___
[Naive Bayes code samples](https://github.com/narekye/machine-learning/tree/master/udacity/udacity/naive_bayes)
> Naive Bayes documentation [sklearn package](http://scikit-learn.org/stable/modules/naive_bayes.html)
<img src="https://github.com/narekye/machine-learning/blob/master/udacity/udacity/data/naive_bayes_classifier.png" align="right" width="300px" height="300px" />
Naive Bayes methods are a set of supervised learning algorithms based on applying Bayes’ theorem with the “naive” assumption of independence between every pair of features. Given a class variable y and a dependent feature vector x_1 through x_n, Bayes’ theorem states the following relationship:

Naive Bayes learners and classifiers can be extremely fast compared to more sophisticated methods. The decoupling of the class conditional feature distributions means that each distribution can be independently estimated as a one dimensional distribution. This in turn helps to alleviate problems stemming from the curse of dimensionality.
